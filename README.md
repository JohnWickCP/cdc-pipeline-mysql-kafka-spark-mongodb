# CDC Pipeline: MySQL ‚Üí Kafka ‚Üí Spark ‚Üí MongoDB

> **ƒê·ªì √°n t·ªët nghi·ªáp** - Change Data Capture pipeline ƒë·ªìng b·ªô d·ªØ li·ªáu g·∫ßn real-time

**T√°c gi·∫£**: Cao Xu√¢n Ph√¥  
**Tr·∫°ng th√°i**: üü° POC Phase - Demo t·ª´ng c√¥ng c·ª• m·ªôt

---

## üìä Progress Tracker

| Phase | Component | Status | Ng√†y ho√†n th√†nh |
|-------|-----------|--------|-----------------|
| 1 | MySQL 8.0 + Binary Log | ‚úÖ Ho√†n th√†nh | 2026-02-24 |
| 2 | MongoDB 7.0 | üü° ƒêang l√†m | TBD |
| 3 | Kafka + Zookeeper | ‚è≥ S·∫Øp t·ªõi | - |
| 4 | Debezium (MySQL‚ÜíKafka) | ‚è≥ S·∫Øp t·ªõi | - |
| 5 | Spark Streaming (Kafka‚ÜíMongoDB) | ‚è≥ S·∫Øp t·ªõi | - |
| 6 | Full Pipeline Integration | ‚è≥ S·∫Øp t·ªõi | - |
| 7 | Testing & Documentation | ‚è≥ S·∫Øp t·ªõi | - |

---

## üõ†Ô∏è Tech Stack

```
MySQL 8.0         ‚Üí Source database (port 3306)
Debezium 2.5      ‚Üí CDC connector (port 8083) 
Kafka 7.5.0       ‚Üí Message broker (port 9092)
Spark 3.5.0       ‚Üí Stream processing (port 8888)
MongoDB 7.0       ‚Üí Target database (port 27017)
Docker 29.x       ‚Üí Containerization
```

---

## üíª H·ªá th·ªëng y√™u c·∫ßu

- **OS**: Linux (Linux Mint 22+, Ubuntu, ...)
- **RAM**: 32GB
- **Disk**: 50GB+ free space
- **Docker**: v29.1.3+
- **Docker Compose**: v5.0.0+

---

## üìã Quick Start

### B∆∞·ªõc 1: Clone repo
```bash
git clone https://github.com/JohnWickCP/cdc-pipeline-mysql-kafka-spark-mongodb.git
cd cdc-pipeline-mysql-kafka-spark-mongodb
```

### B∆∞·ªõc 2: C·∫•u tr√∫c th∆∞ m·ª•c
```bash
mkdir -p {mysql,mongodb,kafka,spark,debezium,pipeline,screenshots}
```

---

## üöÄ Phase 1: MySQL (‚úÖ Ho√†n th√†nh)

### Tr·∫°ng th√°i
- ‚úÖ Docker MySQL image ƒë√£ pull
- ‚úÖ Container ch·∫°y (cdc-mysql)
- ‚úÖ Binary Log b·∫≠t (`--binlog-format=ROW`)
- ‚úÖ Sample data ƒë√£ insert
- ‚úÖ Test connection th√†nh c√¥ng

### Docker Compose
```yaml
# mysql/docker-compose.yml
version: '3.8'
services:
  mysql:
    image: mysql:8.0
    container_name: cdc-mysql
    environment:
      MYSQL_ROOT_PASSWORD: root123
      MYSQL_DATABASE: testdb
      MYSQL_USER: cdc_user
      MYSQL_PASSWORD: cdc123
    ports:
      - "3306:3306"
    command:
      - --server-id=1
      - --log-bin=mysql-bin
      - --binlog-format=ROW
      - --binlog-row-image=FULL
```

### Test MySQL
```bash
docker exec -it cdc-mysql mysql -u root -proot123 testdb
> SHOW MASTER STATUS;           # Ki·ªÉm tra binlog
> SELECT * FROM orders;         # Xem sample data
```

---

## üöÄ Phase 2: MongoDB (üü° ƒêang l√†m)

### M·ª•c ti√™u
- [x] Docker MongoDB image ƒë√£ pull
- [x] Container ch·∫°y (cdc-mongodb)
- [ ] Test k·∫øt n·ªëi th√†nh c√¥ng
- [ ] Sample collections t·∫°o th√†nh c√¥ng
- [ ] Screenshots ch·ª•p & commit

### Docker Compose
File: `mongodb/docker-compose.yml`
```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: cdc-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root123
      MONGO_INITDB_DATABASE: testdb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    restart: unless-stopped
    healthcheck:
      test: echo 'db.adminCommand("ping")' | mongosh --quiet
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  mongodb_data:
    driver: local
```

### B∆∞·ªõc c√†i ƒë·∫∑t & Test

#### Step 1: C·∫≠p nh·∫≠t docker-compose (n·∫øu c·∫ßn)
```bash
cd ~/cdc-pipeline/mongodb

# C·∫≠p nh·∫≠t file v·ªõi volume & healthcheck
cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  mongodb:
    image: mongo:7.0
    container_name: cdc-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: root123
      MONGO_INITDB_DATABASE: testdb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    restart: unless-stopped
    healthcheck:
      test: echo 'db.adminCommand("ping")' | mongosh --quiet
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  mongodb_data:
    driver: local
EOF

# Restart container
docker compose down
docker compose up -d
```

#### Step 2: Ki·ªÉm tra containers ch·∫°y
```bash
docker ps
```
**Expected output**: C·∫£ cdc-mysql v√† cdc-mongodb running

**üì∏ Screenshot name**: `02-mongodb-running.png`
- Ch·ª•p output c·ªßa `docker ps` show c·∫£ MySQL & MongoDB

#### Step 3: Test ping MongoDB
```bash
docker exec -it cdc-mongodb mongosh -u root -p root123 --authenticationDatabase admin testdb --eval "db.adminCommand('ping')"
```
**Expected output**: `{ ok: 1 }`

#### Step 4: T·∫°o collection & insert data m·∫´u
```bash
docker exec -it cdc-mongodb mongosh -u root -p root123 --authenticationDatabase admin testdb << 'EOF'
// T·∫°o collection
db.createCollection('orders')

// Insert sample data
db.orders.insertMany([
  {
    id: 1,
    product: "Laptop",
    quantity: 2,
    price: 1200.00,
    status: "completed",
    created_at: new Date()
  },
  {
    id: 2,
    product: "Mouse",
    quantity: 5,
    price: 25.00,
    status: "pending",
    created_at: new Date()
  },
  {
    id: 3,
    product: "Keyboard",
    quantity: 3,
    price: 75.00,
    status: "completed",
    created_at: new Date()
  }
])

// Hi·ªÉn th·ªã d·ªØ li·ªáu
print("\n=== Data in orders collection ===")
db.orders.find().pretty()
EOF
```

#### Step 5: Verify d·ªØ li·ªáu
```bash
docker exec -it cdc-mongodb mongosh -u root -p root123 --authenticationDatabase admin testdb --eval "db.orders.find().pretty()"
```

**üì∏ Screenshot name**: `03-mongodb-sample-data.png`
- Ch·ª•p output c·ªßa l·ªánh tr√™n, hi·ªÉn th·ªã 3 records

### K·∫øt qu·∫£ mong ƒë·ª£i
```javascript
{
  _id: ObjectId('65d4a1f2b8c9d0e1f2g3h4i5'),
  id: 1,
  product: 'Laptop',
  quantity: 2,
  price: 1200,
  status: 'completed',
  created_at: ISODate('2026-02-24T...')
},
{
  _id: ObjectId('65d4a1f2b8c9d0e1f2g3h4i6'),
  id: 2,
  product: 'Mouse',
  quantity: 5,
  price: 25,
  status: 'pending',
  created_at: ISODate('2026-02-24T...')
},
{
  _id: ObjectId('65d4a1f2b8c9d0e1f2g3h4i7'),
  id: 3,
  product: 'Keyboard',
  quantity: 3,
  price: 75,
  status: 'completed',
  created_at: ISODate('2026-02-24T...')
}
```

### Commit GitHub
```bash
cd ~/cdc-pipeline

# Add files
git add mongodb/docker-compose.yml
git add screenshots/02-mongodb-running.png
git add screenshots/03-mongodb-sample-data.png

# Commit
git commit -m "feat(mongodb): add docker-compose with sample data

- MongoDB 7.0 with root credentials
- Volume for data persistence
- Healthcheck configured
- Sample collection 'orders' with 3 test records
- Screenshots: containers running, sample data"

# Push
git push origin main

# Verify
git log --oneline -2
```

---

## Phase 3: Kafka + Zookeeper (Ho√†n th√†nh)

Status: Completed

### M·ª•c ti√™u
- Zookeeper + Kafka container ch·∫°y
- Test topic creation
- Test message producer/consumer
- Screenshots ch·ª•p & commit

### Docker Compose
File: `kafka/docker-compose.yml`

```yaml
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: cdc-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    restart: unless-stopped
    healthcheck:
      test: echo srvr | nc -w 2 localhost 2181 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: cdc-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
    ports:
      - "9092:9092"
      - "29092:29092"
    restart: unless-stopped
    healthcheck:
      test: kafka-broker-api-versions.sh --bootstrap-server localhost:9092 | head -10
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: cdc-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: cdc-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    ports:
      - "8080:8080"
    restart: unless-stopped
```

### B∆∞·ªõc c√†i ƒë·∫∑t & Test

**Step 1: T·∫°o kafka/docker-compose.yml**
```bash
cd ~/cdc-pipeline
mkdir -p kafka

cat > kafka/docker-compose.yml << 'EOF'
[paste docker-compose.yml above]
EOF
```

**Step 2: Kh·ªüi ƒë·ªông Kafka & Zookeeper**
```bash
cd kafka
docker compose up -d
sleep 20
docker ps
```

Expected: cdc-zookeeper, cdc-kafka, cdc-kafka-ui running

**Screenshot**: `04-kafka-running.png`
- Output c·ªßa `docker ps` show cdc-mysql, cdc-mongodb, cdc-zookeeper, cdc-kafka, cdc-kafka-ui

**Step 3: T·∫°o topic**
```bash
docker exec cdc-kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --create \
  --topic test-topic \
  --partitions 1 \
  --replication-factor 1
```

Expected: `Created topic test-topic.`

**Step 4: List topics**
```bash
docker exec cdc-kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --list
```

Expected: `test-topic`

**Step 5: Test producer (g·ª≠i message)**
```bash
echo -e "Hello Kafka\nMessage 2\nMessage 3" | docker exec -i cdc-kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic test-topic
```

Expected: Kh√¥ng c√≥ output (g·ª≠i th√†nh c√¥ng)

**Step 6: Test consumer (nh·∫≠n message)**
```bash
timeout 5 docker exec cdc-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --from-beginning
```

Expected output:
```
Hello Kafka
Message 2
Message 3
```

**Screenshot**: `05-kafka-producer-consumer.png`
- Output c·ªßa Step 5 + 6 (producer + consumer test)

### Commit GitHub
```bash
cd ~/cdc-pipeline

git add kafka/docker-compose.yml
git add screenshots/04-kafka-running.png
git add screenshots/05-kafka-producer-consumer.png

git commit -m "feat(kafka): add zookeeper and kafka broker with delete.topic.enable

- Zookeeper 7.5.0 for coordination
- Kafka 7.5.0 broker with plaintext protocol
- KAFKA_DELETE_TOPIC_ENABLE=true for topic deletion
- Test topic creation and producer/consumer successful
- Screenshots: containers running, producer/consumer test"

git push origin main
```

## üöÄ Phase 4: Debezium (‚è≥ S·∫Øp t·ªõi)

**M·ª•c ti√™u**: K·∫øt n·ªëi MySQL Binary Log ‚Üí Kafka topics

**D·ª± ki·∫øn**: Sau Kafka ‚úÖ

---

## üöÄ Phase 5: Spark Streaming (‚è≥ S·∫Øp t·ªõi)

**M·ª•c ti√™u**: Consume t·ª´ Kafka ‚Üí X·ª≠ l√Ω ‚Üí Ghi MongoDB

**D·ª± ki·∫øn**: Sau Debezium ‚úÖ

---

## üìÅ C·∫•u tr√∫c Project

```
cdc-pipeline-mysql-kafka-spark-mongodb/
‚îú‚îÄ‚îÄ mysql/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # ‚úÖ Ho√†n th√†nh
‚îú‚îÄ‚îÄ mongodb/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # üü° ƒêang l√†m
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # ‚è≥ S·∫Øp t·ªõi
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # ‚è≥ S·∫Øp t·ªõi
‚îú‚îÄ‚îÄ debezium/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # ‚è≥ S·∫Øp t·ªõi
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml          # ‚è≥ S·∫Øp t·ªõi (full t√≠ch h·ª£p)
‚îú‚îÄ‚îÄ screenshots/                     # Ch·ª©ng minh t·ª´ng b∆∞·ªõc
‚îÇ   ‚îú‚îÄ‚îÄ 01-mysql-running.png        # ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ 02-mongodb-running.png      # üü°
‚îú‚îÄ‚îÄ README.md                        # File n√†y
‚îî‚îÄ‚îÄ .gitignore
```

---

## üì∏ Screenshots

| Phase | Screenshot | M√¥ t·∫£ |
|-------|-----------|-------|
| 1 | `01-mysql-running.png` | MySQL container ch·∫°y + test data |
| 2 | `02-mongodb-running.png` | MongoDB container ch·∫°y + test insert |
| 3 | `03-kafka-running.png` | Kafka + Zookeeper ch·∫°y + test topic |
| 4 | `04-debezium-connector.png` | Debezium connector registered |
| 5 | `05-spark-streaming.png` | Spark jobs consuming Kafka |
| 6 | `06-full-pipeline.png` | Data flow MySQL ‚Üí MongoDB |

---

## üîß L·ªánh h·ªØu √≠ch

```bash
# Ki·ªÉm tra t·∫•t c·∫£ containers
docker ps -a

# View logs
docker logs <container_name> -f

# Connect v√†o container
docker exec -it <container_name> bash

# Remove all containers
docker compose down
docker volume prune

# Rebuild images
docker compose up -d --build

# Git status
git status

# Commit changes
git add .
git commit -m "feat: description"
git push origin main
```

---

## üìù Commit Convention

**Format**: `<type>(<scope>): <subject>`

Examples:
```
feat(mysql): add docker-compose with binlog enabled
feat(mongodb): add docker-compose with healthcheck
fix(kafka): update bootstrap server configuration
docs(readme): add phase 3 instructions
test(debezium): verify connector status endpoint
```

---

## ‚úÖ Checklist - Phase 2 (MongoDB)

- [ ] Docker Compose file t·∫°o
- [ ] Container start th√†nh c√¥ng
- [ ] Test ping MongoDB ‚Üí OK
- [ ] T·∫°o collection 'orders' ‚Üí OK
- [ ] Insert sample data ‚Üí OK
- [ ] Screenshot ch·ª•p ‚Üí l∆∞u v√†o `screenshots/02-mongodb-running.png`
- [ ] Commit l√™n GitHub ‚Üí `git push`
- [ ] Update README.md ‚Üí Mark Phase 2 complete ‚úÖ

---

## üìö References

- [Docker Documentation](https://docs.docker.com/)
- [MongoDB Documentation](https://docs.mongodb.com/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Debezium Documentation](https://debezium.io/documentation/)
- [Apache Spark Documentation](https://spark.apache.org/docs/)

---

---

## Docker Commands Reference

### Container Management
```bash
# Check containers
docker ps                    # Show running containers
docker ps -a                 # Show all containers

# Logs
docker logs <container_name> -f    # View container logs live

# Stop/Start
docker compose down          # Stop all services
docker compose up -d         # Start all services
docker restart <container>   # Restart container
```

### MongoDB Commands
```bash
# Connect to MongoDB
docker exec cdc-mongodb mongosh -u root -p root123 --authenticationDatabase admin testdb

# Inside mongosh:
db.adminCommand("ping")      # Test connection
show collections             # List collections
db.orders.find().pretty()    # View data
db.orders.countDocuments()   # Count records
exit                         # Exit
```

### MySQL Commands
```bash
# Connect to MySQL
docker exec -it cdc-mysql mysql -u root -proot123 testdb

# Inside MySQL:
SHOW MASTER STATUS;          # Check binlog status
SELECT * FROM orders;        # View data
DESC orders;                 # Table structure
exit                         # Exit
```

### Kafka Commands
```bash
# List topics
docker exec cdc-kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --list

# Create topic
docker exec cdc-kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --create \
  --topic <topic-name> \
  --partitions 1 \
  --replication-factor 1

# Delete topic
docker exec cdc-kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --delete \
  --topic <topic-name>

# Producer (send messages)
echo "message" | docker exec -i cdc-kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic <topic-name>

# Consumer (receive messages)
docker exec cdc-kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic <topic-name> \
  --from-beginning
```

### Important Notes
- Use `localhost:9092` for commands inside containers (not `kafka:9092`)
- Use `kafka-topics` (not `kafka-topics.sh`) in Confluent 7.5.0+
- Set `KAFKA_DELETE_TOPIC_ENABLE: "true"` in docker-compose to enable topic deletion

---

## Git Workflow

### Commit Convention
Format: `<type>(<scope>): <subject>`

Types: `feat`, `fix`, `docs`, `test`, `refactor`, `chore`  
Scopes: `mysql`, `mongodb`, `kafka`, `debezium`, `spark`, `readme`, `pipeline`

Examples:
```bash
feat(mongodb): add docker-compose with sample data
fix(kafka): enable topic deletion in docker-compose
docs(readme): update phase 3 completion
```

### Basic Git Commands
```bash
# Check status
git status                   # Show changed files
git log --oneline           # Show commit history

# Add & Commit
git add <file>              # Add single file
git add .                   # Add all changes
git commit -m "message"     # Commit with message

# Push
git push origin main        # Push to GitHub

# Verify
git log --oneline -5        # Show last 5 commits
```

### Typical Workflow per Phase
```bash
# 1. Make changes
# [create/update files]

# 2. Add files
git add <files>

# 3. Commit
git commit -m "feat(<scope>): description"

# 4. Push
git push origin main

# 5. Verify
git log --oneline -2
```

---

## Screenshots

### Phase 1: MySQL
![MySQL Running](screenshots/01-mysql-running.png)
MySQL container + sample data

### Phase 2: MongoDB
![MongoDB Running](screenshots/02-mongodb-running.png)
MySQL + MongoDB containers

![MongoDB Sample Data](screenshots/03-mongodb-sample-data.png)
3 records in orders collection

### Phase 3: Kafka
![Kafka Running](screenshots/04-kafka-running.png)
All containers running (MySQL, MongoDB, Zookeeper, Kafka, Kafka-UI)

![Kafka Producer Consumer](screenshots/05-kafka-producer-consumer.png)
Producer/Consumer test output

### Phase 4: Debezium (Coming Soon)
![Debezium Running](screenshots/06-debezium-running.png)
Debezium connector running

![Debezium Connector Status](screenshots/07-debezium-connector-status.png)
MySQL connector status OK

### Phase 5: Spark (Coming Soon)
![Spark Running](screenshots/08-spark-running.png)
Spark Master + Workers

### Phase 6: Full Pipeline (Coming Soon)
![Full Pipeline Data](screenshots/09-full-pipeline-data.png)
Data flow MySQL ‚Üí MongoDB

---

## Web UIs

| Service | URL | Port | Purpose |
|---------|-----|------|---------|
| Kafka UI | http://localhost:8080 | 8080 | Monitor Kafka topics |
| Mongo Express | http://localhost:8081 | 8081 | Browse MongoDB data |
| Spark Master | http://localhost:8888 | 8888 | Monitor Spark jobs |
| Debezium REST | http://localhost:8083 | 8083 | Manage connectors |

---

## Troubleshooting

### Topic deletion not working
Problem: `delete.topic.enable=false`  
Solution: Add `KAFKA_DELETE_TOPIC_ENABLE: "true"` to Kafka environment, restart

### MongoDB insert not working
Problem: Heredoc fails with docker exec  
Solution: Use `--eval` flag instead of heredoc

### Kafka commands not found
Problem: `kafka-topics.sh not found`  
Solution: Use `kafka-topics` (without .sh) for Confluent 7.5.0+

### TTY error
Problem: `input device is not a TTY`  
Solution: Remove `-it` flag from docker exec

### Port already in use
Solution:
```bash
sudo lsof -i :<port>      # Find process using port
sudo kill -9 <PID>        # Kill process
```

---

**Last Updated**: 2026-02-24